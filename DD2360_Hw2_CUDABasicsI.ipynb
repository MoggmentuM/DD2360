{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Assignment II: CUDA Basics I\n",
        "## [DD2360] Applied GPU Programming\n",
        "Group 8\n",
        "\n",
        "Martin Forslund (uz6@kth.se)\n",
        "| Valeria Grotto (vgrotto@kth.se)\n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "rgeLpcfTrMDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1 - Your first CUDA program and GPU performance metrics\n",
        "This exercise will get you familiar with the basic structure of a simple CUDA code. You will learn how to compile and run CUDA-based programs. You will practice memory allocation in host memory and device memory, the data movement between CPU and GPU, and the distribution of the computational threads in CUDA. You will also use Nvidia Nsight (see the tutorial on [Nsight profiling](https://canvas.kth.se/courses/42842/pages/tutorial-nvidia-nsight-systems-for-profiling?module_item_id=735390)) to profile your program.\n",
        "\n",
        "When comparing the output between CPU and GPU implementation, the precision of the floating-point operations might differ between different versions, which can translate into rounding error differences. Hence, use a margin error range when comparing both versions.\n",
        "\n",
        "Please implement a simple vectorAdd program that sums two vectors and stores the results into a third vector. You will understand how to index 1D arrays inside a GPU kernel. Please complete the following main steps in your code. You can create your own code, or, use the following [code template](https://canvas.kth.se/courses/42842/files/6753924?wrap=1) and edit code parts demarcated by the //@@ comment lines.\n",
        "\n",
        "\n",
        "* Allocate host and device memory\n",
        "* Initialize host memory and create a reference result in CPU memory\n",
        "* Copy from host memory to device memory\n",
        "* Initialize thread block and kernel grid dimensions\n",
        "* Invoke CUDA kernel\n",
        "* Copy results from GPU to CPU\n",
        "* Compare the results with the reference result\n",
        "* Free host and device memory\n",
        "* Write the CUDA kernel\n",
        "\n",
        "***\n",
        "### Questions to answer in the report\n",
        "\n",
        "* Explain how the program is compiled and run.\n",
        "* For a vector length of N:\n",
        "  * How many floating operations are being performed in your vector add kernel?\n",
        "  * How many global memory reads are being performed by your kernel?\n",
        "* For a vector length of 1024:\n",
        "  * Explain how many CUDA threads and thread blocks you used.\n",
        "* Profile your program with Nvidia Nsight.\n",
        "  * What Achieved Occupancy did you get? You might find https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html#nvprof-metric-comparisonLinks to an external site. useful.\n",
        "* Now increase the vector length to 131070:\n",
        "  * Did your program still work? If not, what changes did you make?\n",
        "  * Explain how many CUDA threads and thread blocks you used.\n",
        "* Profile your program with Nvidia Nsight. What Achieved Occupancy do you get now?\n",
        "  * Further increase the vector length (try 6-10 different vector length), plot a stacked bar chart showing the breakdown of time including (1) data copy from host to device (2) the CUDA kernel (3) data copy from device to host. For this, you will need to add simple CPU timers to your code regions.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4dA1jTt0rKHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vectorAdd.cu\n",
        "#include <stdio.h>\n",
        "#include <sys/time.h>\n",
        "\n",
        "// libraries to generate random numbers in C\n",
        "#include <time.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#include <cstdlib> //to convert char* to int\n",
        "\n",
        "// libraries to generate random numbers in CUDA\n",
        "#include <curand_kernel.h>\n",
        "#include <curand.h>\n",
        "\n",
        "#define DataType double\n",
        "#define max_number 100\n",
        "#define minimum_number 0\n",
        "\n",
        "__global__ void vecAdd(DataType *in1, DataType *in2, DataType *out, int len) {\n",
        "    int id = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if(id < len) out[id] = in1[id] + in2[id];\n",
        "}\n",
        "\n",
        "//@@ Insert code to implement timer start\n",
        "//@@ Insert code to implement timer stop\n",
        "DataType cpuSecond() {\n",
        "   struct timeval tp;\n",
        "   gettimeofday(&tp,NULL);\n",
        "   return ((DataType)tp.tv_sec + (DataType)tp.tv_usec*1.e-6);\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "\n",
        "  srand(time(NULL));   // Initialization for random numbers, should only be called once.\n",
        "\n",
        "  int inputLength;\n",
        "  DataType *hostInput1;\n",
        "  DataType *hostInput2;\n",
        "  DataType *hostOutput;\n",
        "  //DataType *resultRef;\n",
        "  DataType *deviceInput1;\n",
        "  DataType *deviceInput2;\n",
        "  DataType *deviceOutput;\n",
        "\n",
        "  //@@ Insert code below to read in inputLength from args\n",
        "  // decode arguments\n",
        "  if(argc < 2) {\n",
        "      printf(\"You must provide at least one argument\\n\");\n",
        "      exit(0);\n",
        "  } else {\n",
        "    inputLength = atoi(argv[1]);\n",
        "  }\n",
        "\n",
        "  printf(\"The input length is %d\\n\", inputLength);\n",
        "\n",
        "  size_t size = inputLength * sizeof(DataType);\n",
        "\n",
        "  //@@ Insert code below to allocate Host memory for input and output\n",
        "  hostInput1 = (DataType *) malloc(size);\n",
        "  hostInput2 = (DataType *) malloc(size);\n",
        "  hostOutput = (DataType *) malloc(size);\n",
        "\n",
        "  //@@ Insert code below to initialize hostInput1 and hostInput2 to random numbers, and create reference result in CPU\n",
        "  for (int i = 0; i < inputLength; i++) {\n",
        "    // generate a pseudo-random integer between minimum_number and max_number\n",
        "    hostInput1[i] = rand() % (max_number + 1 - minimum_number) + minimum_number;\n",
        "    hostInput2[i] = rand() % (max_number + 1 - minimum_number) + minimum_number;\n",
        "  }\n",
        "\n",
        "  //@@ Insert code below to allocate GPU memory here\n",
        "  cudaMalloc((void **)&deviceInput1, size);\n",
        "  cudaMalloc((void **)&deviceInput2, size);\n",
        "  cudaMalloc((void **)&deviceOutput, size);\n",
        "\n",
        "  //@@ Insert code to below to Copy memory to the GPU here\n",
        "  //cudaMemcpy(void* dst, const void* src, size_t count, cudaMemcpyKind kind )\n",
        "  cudaMemcpy(deviceInput1, hostInput1, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(deviceInput2, hostInput2, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  //@@ Initialize the 1D grid and block dimensions here\n",
        "  int dimx = 32;\n",
        "  dim3 block(dimx, 1);\n",
        "  dim3 grid((inputLength + block.x - 1) / block.x, 1);\n",
        "\n",
        "  //@@ Launch the GPU Kernel here\n",
        "  DataType start = cpuSecond();\n",
        "\n",
        "  vecAdd<<<grid, block>>>(deviceInput1, deviceInput2, deviceOutput, inputLength);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  DataType elapsed = cpuSecond() - start;\n",
        "\n",
        "  printf(\"vecAdd<<<(%d,%d), (%d,%d)>>> elapsed %f sec\\n\", grid.x, grid.y, block.x, block.y, elapsed);\n",
        "\n",
        "  //@@ Copy the GPU memory back to the CPU here\n",
        "  cudaMemcpy(hostOutput, deviceOutput, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  //@@ Insert code below to compare the output with the reference\n",
        "  double tolerance = 1.0e-14;\n",
        "  DataType expeted;\n",
        "  for(int i=0; i<inputLength; i++)\n",
        "  {\n",
        "    expeted = hostInput1[i] + hostInput2[i];\n",
        "    //if the absolute value is greater than the tolerance we have an error\n",
        "    if(fabs(hostOutput[i] - expeted) > tolerance)\n",
        "    {\n",
        "        printf(\"\\nError: value of hostOutput[%d] = %f instead of %f\\n\\n\", i, hostOutput[i], expeted);\n",
        "        exit(1);\n",
        "    } else {\n",
        "      //printf(\"\\nOk: value of hostOutput[%d] = %f - expected: %f\\n\\n\", i, hostOutput[i], expeted);\n",
        "    }\n",
        "  }\n",
        "\n",
        "  //@@ Free the GPU memory here\n",
        "  cudaFree(deviceInput1);\n",
        "  cudaFree(deviceInput2);\n",
        "  cudaFree(deviceOutput);\n",
        "\n",
        "\n",
        "  //@@ Free the CPU memory here\n",
        "  free(hostInput1);\n",
        "  free(hostInput2);\n",
        "  free(hostOutput);\n",
        "\n",
        "  printf(\"\\n---------------------------------------------\\n\");\n",
        "  printf(\"SUCCESS\\n\");\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM2-OmRwFG6A",
        "outputId": "0db0ff8f-99c0-48ff-f468-cfa3a068b80c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vectorAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same version of vectorAdd but with a timer added.\n",
        "\n"
      ],
      "metadata": {
        "id": "6eyBdAy_2rnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vectorAdd_2.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <sys/time.h>\n",
        "#include <time.h>\n",
        "#include <stdlib.h>\n",
        "#include <cstdlib> //to convert char* to int\n",
        "#include <curand_kernel.h>\n",
        "#include <curand.h>\n",
        "\n",
        "#define DataType double\n",
        "#define max_number 100\n",
        "#define minimum_number 0\n",
        "\n",
        "__global__ void vecAdd(DataType *in1, DataType *in2, DataType *out, int len) {\n",
        "    int id = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if(id < len) out[id] = in1[id] + in2[id];\n",
        "}\n",
        "\n",
        "DataType cpuSecond() {\n",
        "   struct timeval tp;\n",
        "   gettimeofday(&tp, NULL);\n",
        "   return ((DataType)tp.tv_sec + (DataType)tp.tv_usec * 1.e-6);\n",
        "}\n",
        "\n",
        "//@@ Insert code to implement timer start\n",
        "DataType timerStart;\n",
        "DataType timerStop;\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "  srand(time(NULL));   // Initialization for random numbers, should only be called once.\n",
        "\n",
        "  int inputLength;\n",
        "  DataType *hostInput1;\n",
        "  DataType *hostInput2;\n",
        "  DataType *hostOutput;\n",
        "  DataType *deviceInput1;\n",
        "  DataType *deviceInput2;\n",
        "  DataType *deviceOutput;\n",
        "\n",
        "  //@@ Insert code below to read in inputLength from args\n",
        "  // decode arguments\n",
        "  if (argc < 2) {\n",
        "      printf(\"You must provide at least one argument\\n\");\n",
        "      exit(0);\n",
        "  } else {\n",
        "    inputLength = atoi(argv[1]);\n",
        "  }\n",
        "\n",
        "  printf(\"The input length is %d\\n\", inputLength);\n",
        "\n",
        "  size_t size = inputLength * sizeof(DataType);\n",
        "\n",
        "  //@@ Insert code below to allocate Host memory for input and output\n",
        "  hostInput1 = (DataType *)malloc(size);\n",
        "  hostInput2 = (DataType *)malloc(size);\n",
        "  hostOutput = (DataType *)malloc(size);\n",
        "\n",
        "  //@@ Insert code below to initialize hostInput1 and hostInput2 to random numbers, and create reference result in CPU\n",
        "  for (int i = 0; i < inputLength; i++) {\n",
        "    // generate a pseudo-random integer between minimum_number and max_number\n",
        "    hostInput1[i] = rand() % (max_number + 1 - minimum_number) + minimum_number;\n",
        "    hostInput2[i] = rand() % (max_number + 1 - minimum_number) + minimum_number;\n",
        "  }\n",
        "\n",
        "  //@@ Insert code below to allocate GPU memory here\n",
        "  cudaMalloc((void **)&deviceInput1, size);\n",
        "  cudaMalloc((void **)&deviceInput2, size);\n",
        "  cudaMalloc((void **)&deviceOutput, size);\n",
        "\n",
        "  //@@ Insert code to below to Copy memory to the GPU here\n",
        "  // Timer Start\n",
        "  timerStart = cpuSecond();\n",
        "\n",
        "  cudaMemcpy(deviceInput1, hostInput1, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(deviceInput2, hostInput2, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  // Timer Stop\n",
        "  timerStop = cpuSecond();\n",
        "  DataType copyToDeviceTime = timerStop - timerStart;\n",
        "  printf(\"Data copy from Host to Device elapsed %f sec\\n\", copyToDeviceTime);\n",
        "\n",
        "  //@@ Initialize the 1D grid and block dimensions here\n",
        "  int dimx = 32;\n",
        "  dim3 block(dimx, 1);\n",
        "  dim3 grid((inputLength + block.x - 1) / block.x, 1);\n",
        "\n",
        "  //@@ Launch the GPU Kernel here\n",
        "  // Timer Start\n",
        "  timerStart = cpuSecond();\n",
        "\n",
        "  vecAdd<<<grid, block>>>(deviceInput1, deviceInput2, deviceOutput, inputLength);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // Timer Stop\n",
        "  timerStop = cpuSecond();\n",
        "  DataType kernelTime = timerStop - timerStart;\n",
        "  printf(\"CUDA Kernel elapsed %f sec\\n\", kernelTime);\n",
        "\n",
        "  //@@ Copy the GPU memory back to the CPU here\n",
        "  // Timer Start\n",
        "  timerStart = cpuSecond();\n",
        "\n",
        "  cudaMemcpy(hostOutput, deviceOutput, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // Timer Stop\n",
        "  timerStop = cpuSecond();\n",
        "  DataType copyToHostTime = timerStop - timerStart;\n",
        "  printf(\"Data copy from Device to Host elapsed %f sec\\n\", copyToHostTime);\n",
        "\n",
        "  //@@ Insert code below to compare the output with the reference\n",
        "  double tolerance = 1.0e-14;\n",
        "  DataType expected;\n",
        "  for (int i = 0; i < inputLength; i++) {\n",
        "    expected = hostInput1[i] + hostInput2[i];\n",
        "    // if the absolute value is greater than the tolerance we have an error\n",
        "    if (fabs(hostOutput[i] - expected) > tolerance) {\n",
        "      printf(\"\\nError: value of hostOutput[%d] = %f instead of %f\\n\\n\", i, hostOutput[i], expected);\n",
        "      exit(1);\n",
        "    } else {\n",
        "      // printf(\"\\nOk: value of hostOutput[%d] = %f - expected: %f\\n\\n\", i, hostOutput[i], expected);\n",
        "    }\n",
        "  }\n",
        "\n",
        "  //@@ Free the GPU memory here\n",
        "  cudaFree(deviceInput1);\n",
        "  cudaFree(deviceInput2);\n",
        "  cudaFree(deviceOutput);\n",
        "\n",
        "  //@@ Free the CPU memory here\n",
        "  free(hostInput1);\n",
        "  free(hostInput2);\n",
        "  free(hostOutput);\n",
        "\n",
        "  printf(\"\\n---------------------------------------------\\n\");\n",
        "  printf(\"SUCCESS\\n\");\n",
        "\n",
        "  return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvyZxyH1Hzvm",
        "outputId": "6ad28ea3-33c8-4ae9-a966-8c25fb30326d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vectorAdd_2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile\n"
      ],
      "metadata": {
        "id": "Tg8PRVxrtPOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vectorAdd.cu -o vectorAdd\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl_8PrGItKyR",
        "outputId": "1dacf590-caaa-442d-e7d9-da2a036afdab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  vectorAdd\tvectorAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vectorAdd_2.cu -o vectorAdd2\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1Xp0CYdH-p-",
        "outputId": "b40c6084-c17c-435b-aaa4-b5967cb0b32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.out  matMul  matMul.cu  matrix_multiplication.cu  sample_data  vectorAdd2  vectorAdd_2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running different input lengths 10 times.\n"
      ],
      "metadata": {
        "id": "KKTwZBQJ3DpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! ./vectorAdd2 140000\n",
        "! ./vectorAdd2 150000\n",
        "! ./vectorAdd2 160000\n",
        "! ./vectorAdd2 170000\n",
        "! ./vectorAdd2 180000\n",
        "! ./vectorAdd2 190000\n",
        "! ./vectorAdd2 200000\n",
        "! ./vectorAdd2 210000\n",
        "! ./vectorAdd2 220000\n",
        "! ./vectorAdd2 230000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucaDq2S9S9Ls",
        "outputId": "e149687c-0b3f-4d23-9f35-14213d3c255b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input length is 140000\n",
            "Data copy from Host to Device elapsed 0.000593 sec\n",
            "CUDA Kernel elapsed 0.000069 sec\n",
            "Data copy from Device to Host elapsed 0.000879 sec\n",
            "\n",
            "---------------------------------------------\n",
            "SUCCESS\n",
            "The input length is 150000\n",
            "Data copy from Host to Device elapsed 0.000617 sec\n",
            "CUDA Kernel elapsed 0.000071 sec\n",
            "Data copy from Device to Host elapsed 0.001026 sec\n",
            "\n",
            "---------------------------------------------\n",
            "SUCCESS\n",
            "The input length is 160000\n",
            "Data copy from Host to Device elapsed 0.000630 sec\n",
            "CUDA Kernel elapsed 0.000067 sec\n",
            "Data copy from Device to Host elapsed 0.001031 sec\n",
            "\n",
            "---------------------------------------------\n",
            "SUCCESS\n",
            "The input length is 170000\n",
            "Data copy from Host to Device elapsed 0.000699 sec\n",
            "CUDA Kernel elapsed 0.000059 sec\n",
            "Data copy from Device to Host elapsed 0.001070 sec\n",
            "\n",
            "---------------------------------------------\n",
            "SUCCESS\n",
            "The input length is 180000\n",
            "Data copy from Host to Device elapsed 0.000716 sec\n",
            "CUDA Kernel elapsed 0.000056 sec\n",
            "Data copy from Device to Host elapsed 0.001169 sec\n",
            "\n",
            "---------------------------------------------\n",
            "SUCCESS\n",
            "The input length is 190000\n",
            "Data copy from Host to Device elapsed 0.000751 sec\n",
            "CUDA Kernel elapsed 0.000056 sec\n",
            "Data copy from Device to Host elapsed 0.001198 sec\n",
            "\n",
            "---------------------------------------------\n",
            "SUCCESS\n",
            "The input length is 200000\n",
            "Data copy from Host to Device elapsed 0.000852 sec\n",
            "CUDA Kernel elapsed 0.000053 sec\n",
            "Data copy from Device to Host elapsed 0.001778 sec\n",
            "\n",
            "---------------------------------------------\n",
            "SUCCESS\n",
            "The input length is 210000\n",
            "Data copy from Host to Device elapsed 0.000815 sec\n",
            "CUDA Kernel elapsed 0.000065 sec\n",
            "Data copy from Device to Host elapsed 0.001905 sec\n",
            "\n",
            "---------------------------------------------\n",
            "SUCCESS\n",
            "The input length is 220000\n",
            "Data copy from Host to Device elapsed 0.000856 sec\n",
            "CUDA Kernel elapsed 0.000060 sec\n",
            "Data copy from Device to Host elapsed 0.001329 sec\n",
            "\n",
            "---------------------------------------------\n",
            "SUCCESS\n",
            "The input length is 230000\n",
            "Data copy from Host to Device elapsed 0.000928 sec\n",
            "CUDA Kernel elapsed 0.000081 sec\n",
            "Data copy from Device to Host elapsed 0.001394 sec\n",
            "\n",
            "---------------------------------------------\n",
            "SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for exercise 2 - matrix multiplication.\n",
        "\n",
        "It is currently chosen double as DataType."
      ],
      "metadata": {
        "id": "YBG66QW83QK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matMul.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <sys/time.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "\n",
        "#define DataType float\n",
        "\n",
        "// Compute C = A * B\n",
        "__global__ void gemm(DataType *A, DataType *B, DataType *C, int numARows,\n",
        "                      int numAColumns, int numBRows, int numBColumns){\n",
        "\n",
        "\t //@@ Insert code to implement matrix multiplication here\n",
        "    int rows = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int cols = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "\n",
        "    if(rows < numARows && cols < numBColumns){\n",
        "        DataType sum = 0;\n",
        "        for(int i = 0; i < numAColumns; i++){\n",
        "            sum += A[rows * numAColumns + i] * B[i * numBColumns + cols];\n",
        "        }\n",
        "        C[rows * numBColumns + cols] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "\n",
        "    DataType *hostA; // The A matrix\n",
        "    DataType *hostB; // The B matrix\n",
        "    DataType *hostC; // The output C matrix\n",
        "    DataType *resultRef; // The reference result\n",
        "    DataType *deviceA;\n",
        "    DataType *deviceB;\n",
        "    DataType *deviceC;\n",
        "    int numARows;    // number of rows in the matrix A\n",
        "    int numAColumns; // number of columns in the matrix A\n",
        "    int numBRows;    // number of rows in the matrix B\n",
        "    int numBColumns; // number of columns in the matrix B\n",
        "    int numCRows;\n",
        "    int numCColumns;\n",
        "\n",
        "    //@@ Insert code below to read in numARows, numAColumns, numBColumns and numBRows from args\n",
        "    if(argc != 4){\n",
        "        printf(\"Usage: %s numARows numAColumns numBColumns\\n\", argv[0]);\n",
        "        exit(1);\n",
        "    }\n",
        "    numARows = atoi(argv[1]);\n",
        "    numAColumns = atoi(argv[2]);\n",
        "    numBColumns = atoi(argv[3]);\n",
        "    numBRows = numAColumns;\n",
        "    numCRows = numARows;\n",
        "    numCColumns = numBColumns;\n",
        "    if(numARows <= 0 || numAColumns <= 0 || numBColumns <= 0){\n",
        "        printf(\"Invalid arguments! \\n\");\n",
        "        exit(1);\n",
        "    }\n",
        "\n",
        "     printf(\"Input matrix dimensions: A(%d x %d), B(%d x %d), C(%d x %d)\\n\", numARows, numAColumns, numBRows, numBColumns, numCRows, numCColumns);\n",
        "\n",
        "\n",
        "    //@@ Insert code below to allocate Host memory for input and output\n",
        "    hostA = (DataType*)malloc(numARows * numAColumns * sizeof(DataType));\n",
        "    hostB = (DataType*)malloc(numBRows * numBColumns * sizeof(DataType));\n",
        "\n",
        "    //Checking in order to interrupt memory allocation didnt work.\n",
        "    if(hostA == NULL || hostB == NULL){\n",
        "        printf(\"Allocating memory failed\\n\");\n",
        "        exit(1);\n",
        "    }\n",
        "\n",
        "\n",
        "    //@@ Insert code below to initialize hostA and hostB to random numbers, and create reference result in CPU\n",
        "\n",
        "\n",
        "\n",
        "    for(int i = 0; i < numARows; i++) {\n",
        "        for(int j = 0; j < numAColumns; j++) {\n",
        "            hostA[i * numAColumns + j] = (DataType)rand() / RAND_MAX;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for(int i = 0; i < numBRows; i++) {\n",
        "        for(int j = 0; j < numBColumns; j++) {\n",
        "            hostB[i * numBColumns + j] = (DataType)rand() / RAND_MAX;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Allocate memory for resultRef\n",
        "    resultRef = (DataType*)malloc(numCRows * numCColumns * sizeof(DataType));\n",
        "    if (resultRef == NULL) {\n",
        "        printf(\"Error allocating memory for resultRef\\n\");\n",
        "        exit(1);\n",
        "    }\n",
        "\n",
        "    // Compute the reference result in CPU\n",
        "\n",
        "\n",
        "    for(int i = 0; i < numARows; i++) {\n",
        "        for(int j = 0; j < numBColumns; j++) {\n",
        "            resultRef[i * numBColumns + j] = 0; // Initialize the element to 0\n",
        "            for(int k = 0; k < numAColumns; k++) {\n",
        "                // Accumulate the sum for the dot product of row i from A and column j from B\n",
        "                resultRef[i * numBColumns + j] += hostA[i * numAColumns + k] * hostB[k * numBColumns + j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    hostC = (DataType *)malloc(numCRows * numCColumns * sizeof(DataType));\n",
        "    if(hostA == NULL || hostB == NULL || hostC == NULL || resultRef == NULL){\n",
        "        printf(\"Error allocating memory\\n\");\n",
        "        exit(1);\n",
        "    }\n",
        "\n",
        "    //@@ Insert code below to allocate GPU memory here\n",
        "    cudaMalloc((void **)&deviceA, numARows * numAColumns * sizeof(DataType));\n",
        "    cudaMalloc((void **)&deviceB, numBRows * numBColumns * sizeof(DataType));\n",
        "    cudaMalloc((void **)&deviceC, numCRows * numCColumns * sizeof(DataType));\n",
        "\n",
        "    //@@ Insert code to below to Copy memory to the GPU here\n",
        "\n",
        "    timeval timer;\n",
        "\n",
        "    gettimeofday(&timer, NULL);\n",
        "    double start_memtogpu = timer.tv_sec * 1000000 + timer.tv_usec;\n",
        "\n",
        "\n",
        "    cudaMemcpy(deviceA, hostA, numARows * numAColumns * sizeof(DataType), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(deviceB, hostB, numBRows * numBColumns * sizeof(DataType), cudaMemcpyHostToDevice);\n",
        "\n",
        "    gettimeofday(&timer, NULL);\n",
        "    double end_memtogpu = timer.tv_sec * 1000000 + timer.tv_usec;\n",
        "\n",
        "    double elapsed_time_memtogpu = (end_memtogpu - start_memtogpu) / 1e6;\n",
        "    printf(\"Copy memory to GPU: %f s\\n\", elapsed_time_memtogpu);\n",
        "\n",
        "    //@@ Initialize the grid and block dimensions here\n",
        "    dim3 dimGrid((numBColumns - 1) / 32 + 1, (numARows - 1) / 32 + 1, 1);\n",
        "    dim3 dimBlock(32, 32, 1);\n",
        "\n",
        "    //@@ Launch the GPU Kernel here\n",
        "\n",
        "    gettimeofday(&timer, NULL);\n",
        "    double start_gpukernel = timer.tv_sec * 1000000 + timer.tv_usec;\n",
        "    gemm<<<dimGrid, dimBlock>>>(deviceA, deviceB, deviceC, numARows, numAColumns, numBRows, numBColumns);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    gettimeofday(&timer, NULL);\n",
        "    double end_gpukernel = timer.tv_sec * 1000000 + timer.tv_usec;\n",
        "\n",
        "    double elapsed_time_gpukernel = (end_gpukernel - start_gpukernel) / 1e6;\n",
        "    printf(\"Time to execute the GPU Kernel: %f s\\n\", elapsed_time_gpukernel);\n",
        "\n",
        "\n",
        "    //@@ Copy the GPU memory back to the CPU here\n",
        "\n",
        "    gettimeofday(&timer, NULL);\n",
        "    double start_gputocpu = timer.tv_sec * 1000000 + timer.tv_usec;\n",
        "    cudaMemcpy(hostC, deviceC, numCRows * numCColumns * sizeof(DataType), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    gettimeofday(&timer, NULL);\n",
        "   double end_gputocpu = timer.tv_sec * 1000000 + timer.tv_usec;\n",
        "    double elapsed_time_gputocpu = (end_gputocpu - start_gputocpu) / 1e6;\n",
        "    printf(\"Time to copy from GPU memory to CPU: %f s\\n\", elapsed_time_gputocpu);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    //@@ Insert code below to compare the output with the reference\n",
        "    bool error = false;\n",
        "    for(int i = 0; i < numCRows; i++) {\n",
        "        for(int j = 0; j < numCColumns; j++) {\n",
        "            if(abs(hostC[i * numCColumns + j] - resultRef[i * numCColumns + j]) > 1e-2){\n",
        "                error = true;\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if(error) {\n",
        "        printf(\"The results are incorrect!\\n\");\n",
        "    } else {\n",
        "        printf(\"The results are correct.\\n\");\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    //@@ Free the GPU memory here\n",
        "    cudaFree(deviceA);\n",
        "    cudaFree(deviceB);\n",
        "    cudaFree(deviceC);\n",
        "\n",
        "\n",
        "\n",
        "    //@@ Free the CPU memory here\n",
        "    free(hostA);\n",
        "    free(hostB);\n",
        "    free(hostC);\n",
        "    free(resultRef);\n",
        "\n",
        "\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MEh2HBnZac2",
        "outputId": "f0b03426-5981-43be-d354-ccdc30919e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matMul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile+"
      ],
      "metadata": {
        "id": "iBJDTXCP3ZGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matMul.cu -o matMul"
      ],
      "metadata": {
        "id": "y3lrVtVTZnhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run matMul 10 times, with a beginning of matrix A of 600x1200, matrix B of 1200x2400. up until matrix A 1500x3000, matrix B 3000x6000. with matrix C having 1500x6000"
      ],
      "metadata": {
        "id": "uJaL8AhG3b5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! ./matMul 600 1200 4100\n",
        "! ./matMul 700 1400 4200\n",
        "! ./matMul 800 1600 4300\n",
        "! ./matMul 900 1800 4400\n",
        "! ./matMul 1000 2000 4500\n",
        "! ./matMul 1100 2200 4600\n",
        "! ./matMul 1200 2400 4700\n",
        "! ./matMul 1300 2600 4800\n",
        "! ./matMul 1400 2800 4900\n",
        "! ./matMul 1500 3000 5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT51AYThaQl6",
        "outputId": "efd66817-c231-42db-d79b-f46a14f4b493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input matrix dimensions: A(600 x 1200), B(1200 x 4100), C(600 x 4100)\n",
            "Copy memory to GPU: 0.005111 s\n",
            "Time to execute the GPU Kernel: 0.018735 s\n",
            "Time to copy from GPU memory to CPU: 0.006802 s\n",
            "The results are correct.\n",
            "Input matrix dimensions: A(700 x 1400), B(1400 x 4200), C(700 x 4200)\n",
            "Copy memory to GPU: 0.005908 s\n",
            "Time to execute the GPU Kernel: 0.026306 s\n",
            "Time to copy from GPU memory to CPU: 0.008085 s\n",
            "The results are correct.\n",
            "Input matrix dimensions: A(800 x 1600), B(1600 x 4300), C(800 x 4300)\n",
            "Copy memory to GPU: 0.007240 s\n",
            "Time to execute the GPU Kernel: 0.034814 s\n",
            "Time to copy from GPU memory to CPU: 0.009416 s\n",
            "The results are correct.\n",
            "Input matrix dimensions: A(900 x 1800), B(1800 x 4400), C(900 x 4400)\n",
            "Copy memory to GPU: 0.008441 s\n",
            "Time to execute the GPU Kernel: 0.044493 s\n",
            "Time to copy from GPU memory to CPU: 0.011051 s\n",
            "The results are correct.\n",
            "Input matrix dimensions: A(1000 x 2000), B(2000 x 4500), C(1000 x 4500)\n",
            "Copy memory to GPU: 0.009744 s\n",
            "Time to execute the GPU Kernel: 0.057035 s\n",
            "Time to copy from GPU memory to CPU: 0.012525 s\n",
            "The results are correct.\n",
            "Input matrix dimensions: A(1100 x 2200), B(2200 x 4600), C(1100 x 4600)\n",
            "Copy memory to GPU: 0.011091 s\n",
            "Time to execute the GPU Kernel: 0.070134 s\n",
            "Time to copy from GPU memory to CPU: 0.015393 s\n",
            "The results are correct.\n",
            "Input matrix dimensions: A(1200 x 2400), B(2400 x 4700), C(1200 x 4700)\n",
            "Copy memory to GPU: 0.012745 s\n",
            "Time to execute the GPU Kernel: 0.086925 s\n",
            "Time to copy from GPU memory to CPU: 0.015268 s\n",
            "The results are correct.\n",
            "Input matrix dimensions: A(1300 x 2600), B(2600 x 4800), C(1300 x 4800)\n",
            "Copy memory to GPU: 0.014285 s\n",
            "Time to execute the GPU Kernel: 0.099364 s\n",
            "Time to copy from GPU memory to CPU: 0.017140 s\n",
            "The results are correct.\n",
            "Input matrix dimensions: A(1400 x 2800), B(2800 x 4900), C(1400 x 4900)\n",
            "Copy memory to GPU: 0.015972 s\n",
            "Time to execute the GPU Kernel: 0.123124 s\n",
            "Time to copy from GPU memory to CPU: 0.019334 s\n",
            "The results are correct.\n",
            "Input matrix dimensions: A(1500 x 3000), B(3000 x 5000), C(1500 x 5000)\n",
            "Copy memory to GPU: 0.017403 s\n",
            "Time to execute the GPU Kernel: 0.142589 s\n",
            "Time to copy from GPU memory to CPU: 0.021520 s\n",
            "The results are correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSD-sFcsaaHt",
        "outputId": "b6ea291c-b016-471c-fc2e-e832b118428a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.out  matMul  matMul.cu  matrix_multiplication.cu  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /etc/os-release | grep \"VERSION_ID\"\n",
        "!echo \"Machine's architecture: `uname -i`\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9Pt44QChMPQ",
        "outputId": "b33e3f9a-9dec-41a9-8c05-ddb289b8b055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VERSION_ID=\"22.04\"\n",
            "Machine's architecture: x86_64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "execution with nsight for input length of 1024."
      ],
      "metadata": {
        "id": "pfk1es2B41uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! /usr/local/cuda-11/bin/nv-nsight-cu-cli ./vectorAdd 1024"
      ],
      "metadata": {
        "id": "f2VD5vtS47Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "executing with using nsight for input length of 131070."
      ],
      "metadata": {
        "id": "o_2dUZFT4JAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! /usr/local/cuda-11/bin/nv-nsight-cu-cli ./vectorAdd 131070"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q11a_UvJCRjO",
        "outputId": "d827d575-015d-4537-96d2-d6a26efd8dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==ERROR== './vectorAdd' does not exist or is not an executable. Please make sure to specify the absolute path to './vectorAdd' if the executable is not in the local directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "execution with nsight for a matrix A of (128x128) and B of (128x128)"
      ],
      "metadata": {
        "id": "yvr8X6q-4-5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! /usr/local/cuda-11/bin/nv-nsight-cu-cli ./matMul 128 128 128"
      ],
      "metadata": {
        "id": "NTUD3h-g5IFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "execution with nsight for a matrix A of (511x1023) and B of (1023x4094)"
      ],
      "metadata": {
        "id": "uaY6mr5s5PvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! /usr/local/cuda-11/bin/nv-nsight-cu-cli ./matMul 511 1023 4094"
      ],
      "metadata": {
        "id": "aR15NiLA5Ssd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}